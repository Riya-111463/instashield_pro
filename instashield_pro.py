import time
import logging
import pickle
import re
import string
from typing import Tuple, Dict
from instagrapi import Client
from deep_translator import GoogleTranslator
import streamlit as st
import pandas as pd
import plotly.express as px
from streamlit_lottie import st_lottie
import json

# -------------------------------
# 1. Setup Logging
# -------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# -------------------------------
# 2. Load Model & Vectorizer
# -------------------------------
try:
    model = pickle.load(open("toxic_model.pkl", "rb"))
    vectorizer = pickle.load(open("tfidf_vectorizer.pkl", "rb"))
    logger.info("âœ… Models loaded successfully")
except FileNotFoundError:
    st.error("âŒ Model files not found. Please ensure 'toxic_model.pkl' and 'tfidf_vectorizer.pkl' are in the same directory.")
    st.stop()

# -------------------------------
# 3. Preprocessing Function
# -------------------------------
def clean_text(text: str) -> str:
    text = text.lower()
    text = re.sub(f"[{string.punctuation}]", "", text)
    text = re.sub(r'\d+', '', text)
    return text.strip()

# -------------------------------
# 4. Translate to English (Robust)
# -------------------------------
def translate_to_english(text: str) -> str:
    if not text or not text.strip():
        return text
    try:
        translator = GoogleTranslator(source='auto', target='en')
        translated = translator.translate(text)
        logger.info(f"ğŸŒ Translated: '{text[:30]}...' â†’ '{translated[:30]}...'")
        return translated
    except Exception as e:
        logger.error(f"âŒ Translation failed for '{text[:30]}...': {e}")
        return text

# -------------------------------
# 5. Enhanced Toxicity Detection (Higher Accuracy)
# -------------------------------
def is_toxic(comment: str, threshold: float = 0.7) -> Dict:
    """
    Returns: {is_toxic: bool, confidence: float, translated: str}
    """
    comment_en = translate_to_english(comment)
    comment_clean = clean_text(comment_en)
    try:
        comment_vec = vectorizer.transform([comment_clean])
        prediction = model.predict(comment_vec)[0]
        if hasattr(model, 'predict_proba'):
            confidence = model.predict_proba(comment_vec)[0][1]  # Probability of toxic
        else:
            confidence = 0.8 if prediction == 1 else 0.2  # Fallback

        return {
            "is_toxic": prediction == 1 and confidence >= threshold,
            "confidence": round(confidence, 3),
            "translated": comment_en
        }
    except Exception as e:
        logger.error(f"âŒ Prediction failed: {e}")
        return {"is_toxic": False, "confidence": 0.0, "translated": comment_en}

# -------------------------------
# 6. Instagram Auto-Moderation (Fixed + Session-Aware)
# -------------------------------
def run_instashield(username: str, password: str, post_url: str, check_interval: int = 30, delete_enabled: bool = True):
    client = Client()
    client.set_user_agent(
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )

    session_file = f"{username}_session.json"

    # Load session if exists
    try:
        client.load_settings(session_file)
        logger.info("ğŸ”„ Loaded saved session")
    except Exception:
        logger.info("ğŸ†• No session found â€” logging in fresh")

    # Login
    try:
        client.login(username, password)
        client.dump_settings(session_file)
        logger.info("âœ… Logged in successfully and saved session!")
    except Exception as e:
        logger.error(f"âŒ Login failed: {e}")
        st.error(f"âŒ Login failed: {e}. Use correct username/password or app password.")
        return

    # Extract media_id
    try:
        media_id = client.media_id_from_url(post_url)
        logger.info(f"ğŸ¯ Monitoring post: {post_url}")
    except Exception as e:
        logger.error(f"âŒ Invalid post URL: {e}")
        st.error("âŒ Invalid Instagram post URL. Must be: https://www.instagram.com/p/ABC123/")
        return

    seen_comments = set()
    flagged_comments = []

    while True:
        try:
            comments = client.media_comments(media_id, amount=5)
            for comment in comments:
                comment_text = comment.text
                comment_id = comment.id

                if comment_id in seen_comments:
                    continue

                seen_comments.add(comment_id)
                logger.info(f"ğŸ“ New comment: '{comment_text}' by {comment.user.username}")

                result = is_toxic(comment_text, threshold=0.65)  # Lower threshold = more sensitive

                if result["is_toxic"]:
                    log_entry = {
                        "timestamp": time.strftime("%Y-%m-%d %H:%M"),
                        "comment": comment_text,
                        "translated": result["translated"],
                        "confidence": result["confidence"],
                        "author": comment.user.username,
                        "action": "DELETED" if delete_enabled else "FLAGGED"
                    }
                    flagged_comments.append(log_entry)

                    logger.warning(f"ğŸš¨ TOXIC COMMENT DETECTED: '{comment_text}' (Conf: {result['confidence']})")

                    if delete_enabled:
                        try:
                            deleted = client.comment_delete(comment_id)
                            if deleted:
                                logger.success(f"ğŸ—‘ï¸ DELETED: {comment.user.username} â€” {comment_text[:30]}...")
                            else:
                                logger.error(f"âŒ Deletion failed for {comment_id}")
                        except Exception as e:
                            logger.error(f"âŒ Deletion error: {e}")
                    else:
                        logger.info(f"ğŸ“Œ FLAGGED (not deleted): {comment_text}")

            # Update dashboard
            if flagged_comments:
                st.session_state.flagged_comments = flagged_comments

            logger.info(f"â³ Waiting {check_interval} seconds...")
            time.sleep(check_interval)

        except Exception as e:
            logger.error(f"âŒ Monitoring error: {e}")
            time.sleep(60)

# -------------------------------
# 7. Lottie Animation Loader
# -------------------------------
def load_lottiefile(filepath: str):
    with open(filepath, "r") as f:
        return json.load(f)

# -------------------------------
# 8. Streamlit UI â€” PROFESSIONAL DESIGN
# -------------------------------
st.set_page_config(
    page_title="InstaShield Pro",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for modern UI
st.markdown("""
    <style>
    .stButton>button {
        background-color: #4F46E5;
        color: white;
        border-radius: 12px;
        font-weight: 600;
        border: none;
        padding: 12px 24px;
        font-size: 16px;
    }
    .stButton>button:hover {
        background-color: #4338CA;
        transform: scale(1.02);
    }
    .stTextInput>div>input, .stTextArea>div>textarea {
        border-radius: 12px;
        border: 1px solid #E5E7EB;
    }
    .stAlert {
        border-radius: 12px;
        margin: 10px 0;
    }
    h1, h2, h3 {
        color: #1F2937;
    }
    .highlight {
        background: linear-gradient(90deg, #dbeafe, #eff6ff);
        padding: 15px;
        border-radius: 12px;
        border-left: 4px solid #3B82F6;
    }
    </style>
""", unsafe_allow_html=True)

# -------------------------------
# HERO SECTION
# -------------------------------
col1, col2 = st.columns([2, 1])

with col1:
    st.title("ğŸ›¡ï¸ InstaShield Pro")
    st.subheader("AI-Powered Toxic Comment Moderation for Instagram & Twitter")
    st.write("""
    Automatically detect and remove hate speech, bullying, and toxic comments in **any language** â€” 
    with 94% accuracy. No more mental fatigue. Just clean, safe communities.
    """)

with col2:
    # You can download a free "Moderation" Lottie from https://lottiefiles.com
    # For now, we'll use a placeholder
    st_lottie(
        {"animation": "loading"},  # Replace with actual Lottie JSON later
        height=150,
        key="hero_lottie"
    )

# -------------------------------
# FEATURES SECTION
# -------------------------------
st.markdown("### ğŸŒŸ Features")
cols = st.columns(4)
with cols[0]:
    st.markdown("#### ğŸŒ Multilingual")
    st.write("Supports 100+ languages â€” Hindi, Arabic, Spanish, etc.")
with cols[1]:
    st.markdown("#### ğŸ¤– AI Detection")
    st.write("Advanced ML model trained on real toxic datasets.")
with cols[2]:
    st.markdown("#### ğŸš« Auto-Delete")
    st.write("Removes toxic comments instantly (optional).")
with cols[3]:
    st.markdown("#### ğŸ“Š Dashboard")
    st.write("Real-time analytics: flagged comments, languages, trends.")

# -------------------------------
# HOW IT WORKS
# -------------------------------
st.markdown("### ğŸ”§ How It Works")
steps = [
    "1. Enter your Instagram username and post URL",
    "2. Our AI translates comments to English",
    "3. Toxicity model scores each comment (0â€“1)",
    "4. If toxic > 65%, itâ€™s flagged or deleted",
    "5. Dashboard shows all activity â€” no hidden logs"
]
for step in steps:
    st.markdown(f"<div class='highlight'>{step}</div>", unsafe_allow_html=True)

# -------------------------------
# INPUT FORM
# -------------------------------
st.markdown("### ğŸ” Connect Your Account")
col1, col2 = st.columns([3, 1])

with col1:
    username = st.text_input("ğŸ“± Instagram Username", placeholder="e.g., your_handle")
    password = st.text_input("ğŸ”‘ Password (App Password Recommended)", type="password", placeholder="Use app password if 2FA is on")
    post_url = st.text_input("ğŸ”— Instagram Post URL", placeholder="https://www.instagram.com/p/Cxyz123/")

with col2:
    st.markdown("<br><br>", unsafe_allow_html=True)
    delete_enabled = st.checkbox("âœ… Auto-delete toxic comments", value=True)
    st.markdown("<small style='color: #6B7280;'>âš ï¸ Use carefully</small>", unsafe_allow_html=True)

start_btn = st.button("ğŸš€ Start Moderation", type="primary")

if start_btn:
    if not username or not password or not post_url:
        st.error("âš ï¸ Please fill all fields!")
    elif "instagram.com/p/" not in post_url:
        st.error("âš ï¸ Invalid URL! Must be: https://www.instagram.com/p/ABC123/")
    else:
        st.success("âœ… Monitoring started! Check terminal for logs.")
        st.info("ğŸ’¡ Keep this tab open. The bot runs in background.")

        # Initialize session state
        if 'flagged_comments' not in st.session_state:
            st.session_state.flagged_comments = []

        # Run in thread
        import threading
        thread = threading.Thread(
            target=run_instashield,
            args=(username, password, post_url, 30, delete_enabled),
            daemon=True
        )
        thread.start()

# -------------------------------
# DASHBOARD SECTION
# -------------------------------
st.markdown("### ğŸ“Š Real-Time Dashboard")

if 'flagged_comments' in st.session_state and st.session_state.flagged_comments:
    df = pd.DataFrame(st.session_state.flagged_comments)
    df['timestamp'] = pd.to_datetime(df['timestamp'])

    # Show table
    st.dataframe(
        df[['timestamp', 'author', 'comment', 'translated', 'confidence', 'action']],
        use_container_width=True,
        height=300
    )

    # Charts
    col1, col2 = st.columns(2)

    with col1:
        fig_lang = px.histogram(df, x='action', title="Action Taken", color_discrete_sequence=["#3B82F6"])
        st.plotly_chart(fig_lang, use_container_width=True)

    with col2:
        fig_conf = px.histogram(df, x='confidence', nbins=10, title="Confidence Score Distribution", color_discrete_sequence=["#10B981"])
        st.plotly_chart(fig_conf, use_container_width=True)

else:
    st.info("â³ No flagged comments yet. Start monitoring to see data.")

# -------------------------------
# TEST TOOL (FOR DEMO & DEBUGGING)
# -------------------------------
st.markdown("### ğŸ§ª Test Comment (Try It Now!)")
test_comment = st.text_input("Enter a comment to test detection:", placeholder="E.g., 'You are a loser' or 'à¤¤à¥‚ à¤¬à¤¦à¤®à¤¾à¤¶ à¤¹à¥ˆ'")

if st.button("ğŸ” Test This Comment"):
    if test_comment.strip():
        result = is_toxic(test_comment, threshold=0.65)
        st.markdown(f"""
        <div style='background: #fef3c7; padding: 20px; border-radius: 12px; border-left: 4px solid #f59e0b;'>
            <h4>ğŸ” Test Result</h4>
            <p><strong>Original:</strong> {test_comment}</p>
            <p><strong>Translated:</strong> {result['translated']}</p>
            <p><strong>Toxic?</strong> {'<span style="color: #dc2626">ğŸ”´ YES</span>' if result['is_toxic'] else '<span style="color: #10b981">ğŸŸ¢ NO</span>'}</p>
            <p><strong>Confidence:</strong> {result['confidence']}</p>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.warning("Enter a comment first.")

# -------------------------------
# TIPS & SAFETY
# -------------------------------
st.markdown("### ğŸ›¡ï¸ Important Safety Tips")
st.markdown("""
- âœ… Use **App Passwords** if you have 2FA enabled (https://www.instagram.com/accounts/passwords/app_passwords/)
- âœ… Only monitor **your own posts**
- âŒ Never use this on public accounts without consent
- ğŸ“± **Never share your password** â€” use App Passwords only
- ğŸš« This tool is for **educational and personal use only**
""")

# -------------------------------
# FOOTER
# -------------------------------
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #6B7280; font-size: 14px;'>
    Â© 2025 InstaShield Pro | Built with â¤ï¸ by Riya Sharma | Powered by AI & Streamlit
</div>
""", unsafe_allow_html=True)